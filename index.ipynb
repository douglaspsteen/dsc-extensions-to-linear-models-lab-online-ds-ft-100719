{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate object of boston dataset from sklearn\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features (X) and target (y) as pandas DataFrames\n",
    "X = pd.DataFrame(data=boston.data, columns = boston.feature_names)\n",
    "y = pd.DataFrame(data=boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create scaled version of X\n",
    "X_scaled = scale(X)\n",
    "X_scaled = pd.DataFrame(data=X_scaled, columns = X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7176778617934925\n"
     ]
    }
   ],
   "source": [
    "# Build at a baseline model using scaled variables as predictors. \n",
    "# Use 5-fold cross-validation (set random_state to 1) and use the  ùëÖ2  score to evaluate the model\n",
    "\n",
    "cross_val = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "linreg = LinearRegression()\n",
    "baseline = np.mean(cross_val_score(linreg, X_scaled, y=y, scoring='r2', cv=cross_val))\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('RM', 'LSTAT'), 0.7832011303731377), (('RM', 'TAX'), 0.7752682934529788), (('RM', 'RAD'), 0.770118390390615), (('RM', 'PTRATIO'), 0.7635941716268361), (('INDUS', 'RM'), 0.7566278048616748), (('NOX', 'RM'), 0.7461114895799352), (('RM', 'AGE'), 0.7421409891793225)]\n"
     ]
    }
   ],
   "source": [
    "# Create list of all combinations of features\n",
    "combs = list(combinations(X.columns, 2))\n",
    "X_int = X_scaled.copy()\n",
    "\n",
    "interactions = []\n",
    "for comb in combs:\n",
    "\n",
    "    int_term = X_int[comb[0]]*X[comb[1]]\n",
    "    X_int['int_term'] = int_term\n",
    "    \n",
    "    cross_val = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    linreg = LinearRegression()\n",
    "    \n",
    "    mod_score = np.mean(cross_val_score(linreg, X_int, y=y, scoring='r2', cv=cross_val))\n",
    "    interactions.append((comb, mod_score))\n",
    "    top_seven = sorted(interactions, key = lambda x: x[1], reverse=True)[:7]\n",
    "    \n",
    "print(top_seven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_int = X_scaled.copy()\n",
    "\n",
    "for i in top_seven:\n",
    "    X_all_int[f'{i[0][0]}_{i[0][1]}'] = X_all_int[i[0][0]] * X_all_int[i[0][1]]\n",
    "    \n",
    "X_all_int.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', 2, 0.717),\n",
       " ('CRIM', 3, 0.716),\n",
       " ('CRIM', 4, 0.714),\n",
       " ('ZN', 2, 0.72),\n",
       " ('ZN', 3, 0.723),\n",
       " ('ZN', 4, 0.72),\n",
       " ('INDUS', 2, 0.723),\n",
       " ('INDUS', 3, 0.723),\n",
       " ('INDUS', 4, 0.723),\n",
       " ('CHAS', 2, 0.718),\n",
       " ('CHAS', 3, 0.718),\n",
       " ('CHAS', 4, 0.718),\n",
       " ('NOX', 2, 0.718),\n",
       " ('NOX', 3, 0.718),\n",
       " ('NOX', 4, 0.721),\n",
       " ('RM', 2, 0.782),\n",
       " ('RM', 3, 0.781),\n",
       " ('RM', 4, 0.8),\n",
       " ('AGE', 2, 0.721),\n",
       " ('AGE', 3, 0.722),\n",
       " ('AGE', 4, 0.722),\n",
       " ('DIS', 2, 0.732),\n",
       " ('DIS', 3, 0.737),\n",
       " ('DIS', 4, 0.731),\n",
       " ('RAD', 2, 0.716),\n",
       " ('RAD', 3, 0.716),\n",
       " ('RAD', 4, 0.72),\n",
       " ('TAX', 2, 0.719),\n",
       " ('TAX', 3, 0.721),\n",
       " ('TAX', 4, 0.724),\n",
       " ('PTRATIO', 2, 0.721),\n",
       " ('PTRATIO', 3, 0.719),\n",
       " ('PTRATIO', 4, 0.717),\n",
       " ('B', 2, 0.72),\n",
       " ('B', 3, 0.719),\n",
       " ('B', 4, 0.718),\n",
       " ('LSTAT', 2, 0.772),\n",
       " ('LSTAT', 3, 0.774),\n",
       " ('LSTAT', 4, 0.782)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polynomials = []\n",
    "\n",
    "for col in X_scaled.columns:\n",
    "    for power in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        \n",
    "        # Apply polynomial tranformation to variable\n",
    "        poly = PolynomialFeatures(degree=power, include_bias=False)\n",
    "        poly_feature = poly.fit_transform(data[[col]])\n",
    "        \n",
    "        # Add transformed variable to dataframe, drop original variable\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(poly_feature)], axis=1)\n",
    "        \n",
    "        # Instantiate K-fold cross val and linreg objects\n",
    "        cross_val = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        linreg = LinearRegression()\n",
    "        \n",
    "        # Get mean r^2 from cross_val_score, append results to polynomials list\n",
    "        score = np.mean(cross_val_score(linreg, data, y=y, scoring='r2', cv=cross_val))\n",
    "        polynomials.append((col, power, round(score, 3)))\n",
    "\n",
    "display(polynomials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "AGE        0.722\n",
       "B          0.720\n",
       "CHAS       0.718\n",
       "CRIM       0.717\n",
       "DIS        0.737\n",
       "INDUS      0.723\n",
       "LSTAT      0.782\n",
       "NOX        0.721\n",
       "PTRATIO    0.721\n",
       "RAD        0.720\n",
       "RM         0.800\n",
       "TAX        0.724\n",
       "ZN         0.723\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df = pd.DataFrame(polynomials)\n",
    "p_df.groupby([0]).max()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RM and LSTAT seem to benefit the most from adding polynomial terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = X_all_int.copy()\n",
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "    feature = poly.fit_transform(X_scaled[[col]])\n",
    "    colnames = [col, col + '_' + '2', col + '_' + '3', col + '_' + '4']\n",
    "    df_all = pd.concat([df_all.drop(col, axis=1), pd.DataFrame(feature, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>1.156834</td>\n",
       "      <td>-1.244247</td>\n",
       "      <td>1.338266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>0.242497</td>\n",
       "      <td>-0.119415</td>\n",
       "      <td>0.058805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>1.645354</td>\n",
       "      <td>2.110519</td>\n",
       "      <td>2.707191</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>1.461022</td>\n",
       "      <td>-1.765977</td>\n",
       "      <td>2.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>1.032871</td>\n",
       "      <td>1.049709</td>\n",
       "      <td>1.066822</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>1.853728</td>\n",
       "      <td>-2.523882</td>\n",
       "      <td>3.436308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>1.509401</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>2.278290</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>1.053705</td>\n",
       "      <td>-1.081630</td>\n",
       "      <td>1.110295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...    NOX_RM    RM_AGE        RM      RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ... -0.059659 -0.049646  0.413672  0.171124   \n",
       "1 -0.867883 -0.987329 -0.303094  ... -0.143814  0.071331  0.194274  0.037743   \n",
       "2 -0.867883 -0.987329 -0.303094  ... -0.949544 -0.340960  1.282714  1.645354   \n",
       "3 -0.752922 -1.106115  0.113032  ... -0.848901 -0.823092  1.016303  1.032871   \n",
       "4 -0.752922 -1.106115  0.113032  ... -1.026210 -0.628023  1.228577  1.509401   \n",
       "\n",
       "       RM_3      RM_4     LSTAT   LSTAT_2   LSTAT_3   LSTAT_4  \n",
       "0  0.070789  0.029284 -1.075562  1.156834 -1.244247  1.338266  \n",
       "1  0.007332  0.001425 -0.492439  0.242497 -0.119415  0.058805  \n",
       "2  2.110519  2.707191 -1.208727  1.461022 -1.765977  2.134585  \n",
       "3  1.049709  1.066822 -1.361517  1.853728 -2.523882  3.436308  \n",
       "4  1.854414  2.278290 -1.026501  1.053705 -1.081630  1.110295  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8061549447223175\n"
     ]
    }
   ],
   "source": [
    "full_r2 = np.mean(cross_val_score(linreg, df_all, y=y, scoring='r2', cv=cross_val))\n",
    "print(full_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic = LassoLarsIC(criterion='aic')\n",
    "aic.fit(df_all, y)\n",
    "alpha_aic = aic.alphas_\n",
    "crit_aic = aic.criterion_\n",
    "\n",
    "bic = LassoLarsIC(criterion='bic')\n",
    "bic.fit(df_all, y)\n",
    "alpha_bic = bic.alphas_\n",
    "crit_bic = bic.criterion_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(-np.log10(alpha_aic), crit_aic, ls='--', c='red', label='AIC')\n",
    "plt.plot(-np.log10(alpha_bic), crit_bic, ls='--', c='green', label='BIC')\n",
    "plt.axvline(x=-np.log10(aic.alpha_), c='red', label='AIC alpha')\n",
    "plt.axvline(x=-np.log10(bic.alpha_), c='green', label='BIC alpha')\n",
    "plt.xlabel('- log10(alpha)')\n",
    "plt.ylabel('Criterion')\n",
    "plt.legend()\n",
    "plt.title('Regularization Parameter (alpha) Optimization for AIC/BIC')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE MODEL (no lasso)\n",
      "Train R^2: 0.7168057552393374\n",
      "Test R^2: 0.7789410172622857\n",
      "Train MSE: 22.477983821877896\n",
      "Test MSE: 21.897765396049497\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "b_model = linreg_all.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('BASELINE MODEL (no lasso)')\n",
    "print(f'Train R^2: {b_model.score(X_train, y_train)}')\n",
    "print(f'Test R^2: {b_model.score(X_test, y_test)}')\n",
    "\n",
    "print(f'Train MSE: {mean_squared_error(y_train, linreg_all.predict(X_train))}')\n",
    "print(f'Test MSE: {mean_squared_error(y_test, linreg_all.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC LASSO MODEL\n",
      "Train R^2: 0.8318173711708374\n",
      "Test R^2: 0.8548188862719713\n",
      "Train MSE: 13.349163974493079\n",
      "Test MSE: 14.381419515196074\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha=aic.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('AIC LASSO MODEL')\n",
    "print(f'Train R^2: {lasso.score(X_train, y_train)}')\n",
    "print(f'Test R^2: {lasso.score(X_test, y_test)}')\n",
    "\n",
    "print(f'Train MSE: {mean_squared_error(y_train, lasso.predict(X_train))}')\n",
    "print(f'Test MSE: {mean_squared_error(y_test, lasso.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC LASSO MODEL\n",
      "Train R^2: 0.8289395133356199\n",
      "Test R^2: 0.8619985551393498\n",
      "Train MSE: 13.577588255912904\n",
      "Test MSE: 13.670212476549205\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha=bic.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('BIC LASSO MODEL')\n",
    "print(f'Train R^2: {lasso.score(X_train, y_train)}')\n",
    "print(f'Test R^2: {lasso.score(X_test, y_test)}')\n",
    "\n",
    "print(f'Train MSE: {mean_squared_error(y_train, lasso.predict(X_train))}')\n",
    "print(f'Test MSE: {mean_squared_error(y_test, lasso.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
